{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13817018,"sourceType":"datasetVersion","datasetId":8798692},{"sourceId":13817007,"sourceType":"datasetVersion","datasetId":8798681}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:16:24.321070Z","iopub.execute_input":"2025-11-29T08:16:24.321386Z","iopub.status.idle":"2025-11-29T08:16:26.626208Z","shell.execute_reply.started":"2025-11-29T08:16:24.321355Z","shell.execute_reply":"2025-11-29T08:16:26.625258Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install dependencies\n!pip install timm opencv-python matplotlib pillow --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:17:27.586502Z","iopub.execute_input":"2025-11-29T08:17:27.586834Z","iopub.status.idle":"2025-11-29T08:18:51.242822Z","shell.execute_reply.started":"2025-11-29T08:17:27.586810Z","shell.execute_reply":"2025-11-29T08:18:51.240853Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install mmengine --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:23:04.315842Z","iopub.execute_input":"2025-11-29T08:23:04.316531Z","iopub.status.idle":"2025-11-29T08:23:13.334281Z","shell.execute_reply.started":"2025-11-29T08:23:04.316503Z","shell.execute_reply":"2025-11-29T08:23:13.333512Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install mmengine mmcv-lite --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:23:13.335640Z","iopub.execute_input":"2025-11-29T08:23:13.335950Z","iopub.status.idle":"2025-11-29T08:23:17.184932Z","shell.execute_reply.started":"2025-11-29T08:23:13.335925Z","shell.execute_reply":"2025-11-29T08:23:17.184192Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# Kaggle-Optimized Metric3D Evaluation on KITTI\n# ============================================================\n\nimport torch\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport time\nimport json\nfrom tqdm import tqdm\n\n\nclass Metric3DKITTITester:\n    def __init__(self, hub_model='metric3d_vit_small', device='cuda'):\n        \"\"\"\n        Kaggle-optimized Metric3D evaluation.\n        hub_model options:\n            - metric3d_convnext_tiny   (CPU safe)\n            - metric3d_convnext_large\n            - metric3d_vit_small       (best on GPU)\n            - metric3d_vit_large\n            - metric3d_vit_giant2\n        \"\"\"\n        self.hub_model = hub_model\n        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n        self.model = None\n\n        print(f\"ğŸš€ Using device: {self.device}\")\n        print(f\"ğŸ“¦ Model: {self.hub_model}\")\n\n    # ---------------------- MODEL LOADING ----------------------\n    def load_model(self):\n        print(\"ğŸ“¥ Loading Metric3D via PyTorch Hub...\")\n\n        try:\n            self.model = torch.hub.load(\n                'yvanyin/metric3d',\n                self.hub_model,\n                pretrain=True,\n                trust_repo=True\n            ).to(self.device)\n\n            self.model.eval()\n            print(\"âœ… Metric3D loaded successfully!\")\n            return True\n\n        except Exception as e:\n            print(f\"âŒ Error loading model: {e}\")\n            return False\n\n    # ---------------------- KITTI DEPTH LOADING ----------------------\n    def load_kitti_depth(self, depth_path):\n        depth = cv2.imread(str(depth_path), cv2.IMREAD_ANYDEPTH).astype(np.float32)\n        depth /= 256.0\n        valid_mask = depth > 0\n        return depth, valid_mask\n\n    # ---------------------- PREDICTION ----------------------\n    def predict_depth(self, image_path):\n        \"\"\"GPU-accelerated inference with AMP for ViT models\"\"\"\n        start_time = time.time()\n\n        image = Image.open(str(image_path)).convert(\"RGB\")\n        img_np = np.array(image)\n\n        img = torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.\n        img = img.unsqueeze(0).to(self.device)\n\n        with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n            pred_depth, confidence, out_dict = self.model.inference({\"input\": img})\n            pred_depth = pred_depth[0, 0].detach().cpu().numpy()\n\n        return pred_depth, time.time() - start_time\n\n    # ---------------------- METRIC COMPUTATION ----------------------\n    def compute_metrics(self, pred, gt, valid):\n        pred = pred[valid]\n        gt = gt[valid]\n\n        pred = np.clip(pred, 1e-3, None)\n        gt = np.clip(gt, 1e-3, None)\n\n        thresh = np.maximum(gt / pred, pred / gt)\n\n        return {\n            \"delta_1\": float((thresh < 1.25).mean()),\n            \"delta_2\": float((thresh < 1.25 ** 2).mean()),\n            \"delta_3\": float((thresh < 1.25 ** 3).mean()),\n            \"rmse\": float(np.sqrt(((pred - gt) ** 2).mean())),\n            \"rmse_log\": float(np.sqrt(((np.log(pred) - np.log(gt)) ** 2).mean())),\n            \"mae\": float(np.abs(pred - gt).mean()),\n            \"abs_rel\": float((np.abs(pred - gt) / gt).mean()),\n            \"sq_rel\": float((((pred - gt) ** 2) / gt).mean())\n        }\n\n    # ---------------------- VISUALIZATION ----------------------\n    def visualize_result(self, image_path, pred_depth, gt_depth, valid_mask, metrics, output_path):\n        image = np.array(Image.open(image_path).convert('RGB'))\n\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n        # Input Image\n        axes[0, 0].imshow(image)\n        axes[0, 0].set_title('Input Image')\n        axes[0, 0].axis('off')\n\n        # Pred Depth\n        im1 = axes[0, 1].imshow(pred_depth, cmap='plasma', vmin=0, vmax=80)\n        axes[0, 1].set_title('Metric3D Depth')\n        axes[0, 1].axis('off')\n        plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, label='meters')\n\n        # GT\n        gt_disp = gt_depth.copy()\n        gt_disp[~valid_mask] = np.nan\n        im2 = axes[1, 0].imshow(gt_disp, cmap='plasma', vmin=0, vmax=80)\n        axes[1, 0].set_title('Ground Truth')\n        axes[1, 0].axis('off')\n        plt.colorbar(im2, ax=axes[1, 0], fraction=0.046, label='meters')\n\n        # Error\n        err = np.abs(pred_depth - gt_depth)\n        err[~valid_mask] = np.nan\n        im3 = axes[1, 1].imshow(err, cmap='hot', vmin=0, vmax=10)\n        axes[1, 1].set_title('Absolute Error')\n        axes[1, 1].axis('off')\n        plt.colorbar(im3, ax=axes[1, 1], fraction=0.046, label='meters')\n\n        # Metric text\n        text = '\\n'.join([f'{k}: {v:.4f}' for k, v in metrics.items() if k != 'inference_time'])\n        fig.text(0.02, 0.02, text, fontsize=10, family='monospace',\n                 bbox=dict(boxstyle='round', facecolor='wheat'))\n\n        plt.tight_layout()\n        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n        plt.close()\n\n    # ---------------------- MAIN KITTI LOOP ----------------------\n    def test_on_kitti(self, image_dir, gt_dir, output_dir, num_samples=20):\n        image_dir = Path(image_dir)\n        gt_dir = Path(gt_dir)\n        output_dir = Path(output_dir)\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n        image_files = sorted(image_dir.glob(\"*.png\"))\n        image_files = image_files[:num_samples]\n\n        print(f\"ğŸ“ Evaluating {len(image_files)} images...\\n\")\n        all_metrics = []\n\n        for idx, img_path in tqdm(list(enumerate(image_files)), total=len(image_files)):\n            pred, t = self.predict_depth(img_path)\n\n            gt_path = gt_dir / img_path.name\n            gt_depth, mask = self.load_kitti_depth(gt_path)\n\n            pred = cv2.resize(pred, (gt_depth.shape[1], gt_depth.shape[0]))\n\n            metrics = self.compute_metrics(pred, gt_depth, mask)\n            metrics[\"inference_time\"] = t\n            all_metrics.append(metrics)\n\n            vis_path = output_dir / f\"result_{idx:03d}_{img_path.stem}.png\"\n            self.visualize_result(img_path, pred, gt_depth, mask, metrics, vis_path)\n\n        # Save metrics.json\n        avg = {k: float(np.mean([m[k] for m in all_metrics])) for k in all_metrics[0]}\n        results_path = output_dir / \"metrics.json\"\n\n        json.dump({\n            \"average\": avg,\n            \"per_image\": all_metrics\n        }, open(results_path, \"w\"), indent=2)\n\n        print(f\"\\nğŸ’¾ Saved metrics to: {results_path}\")\n\n\n# =====================================================\n# MAIN (Kaggle paths)\n# =====================================================\n\nIMAGE_DIR = \"/kaggle/input/images-test\"\nGT_DIR = \"/kaggle/input/ground-truth\"\nOUTPUT_DIR = \"/kaggle/working/metric3d_results\"\nNUM_SAMPLES = 20\n\ntester = Metric3DKITTITester(\n    hub_model=\"metric3d_vit_small\",\n    device=\"cuda\"\n)\n\nif tester.load_model():\n    tester.test_on_kitti(IMAGE_DIR, GT_DIR, OUTPUT_DIR, NUM_SAMPLES)\n\nprint(\"\\nâœ… Done!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:23:32.958405Z","iopub.execute_input":"2025-11-29T08:23:32.959309Z","iopub.status.idle":"2025-11-29T08:24:12.249160Z","shell.execute_reply.started":"2025-11-29T08:23:32.959273Z","shell.execute_reply":"2025-11-29T08:24:12.248268Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Using device: cuda\nğŸ“¦ Model: metric3d_vit_small\nğŸ“¥ Loading Metric3D via PyTorch Hub...\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/yvanyin_metric3d_main\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\nxFormers not available\nxFormers not available\nxFormers not available\nxFormers not available\nDownloading: \"https://huggingface.co/JUGGHM/Metric3D/resolve/main/metric_depth_vit_small_800k.pth\" to /root/.cache/torch/hub/checkpoints/metric_depth_vit_small_800k.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143M/143M [00:00<00:00, 304MB/s] \n","output_type":"stream"},{"name":"stdout","text":"âœ… Metric3D loaded successfully!\nğŸ“ Evaluating 20 images...\n\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/20 [00:00<?, ?it/s]/tmp/ipykernel_47/3172600041.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:29<00:00,  1.49s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ’¾ Saved metrics to: /kaggle/working/metric3d_results/metrics.json\n\nâœ… Done!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\nOUTPUT_DIR = \"/kaggle/working/metric3d_results\"\nZIP_PATH = \"/kaggle/working/metric3d_results\"\n\nprint(\"ğŸ“¦ Creating ZIP file...\")\n\n# Create ZIP of entire directory\nshutil.make_archive(ZIP_PATH, 'zip', OUTPUT_DIR)\n\nprint(f\"âœ… ZIP created at: {ZIP_PATH}.zip\")\nprint(\"You can now download the file from the Kaggle sidebar (Output > Files).\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:28:18.446730Z","iopub.execute_input":"2025-11-29T08:28:18.447547Z","iopub.status.idle":"2025-11-29T08:28:19.067151Z","shell.execute_reply.started":"2025-11-29T08:28:18.447522Z","shell.execute_reply":"2025-11-29T08:28:19.066335Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Creating ZIP file...\nâœ… ZIP created at: /kaggle/working/metric3d_results.zip\nYou can now download the file from the Kaggle sidebar (Output > Files).\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}